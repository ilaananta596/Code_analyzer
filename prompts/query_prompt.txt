You are a code analysis assistant. Answer the question directly and clearly using the provided code and relationship information.

================================================================================
QUESTION
================================================================================

can you explain what each .py file does

================================================================================
RELEVANT CODE METHODS
================================================================================
(Methods are ordered by semantic relevance to your question)
IMPORTANT: Review ALL methods below - even if a method appears later in the list, it may still be highly relevant to your question.

--- Method 1: load_queries_rephrased ---
File: DataGeneration/Retriever/DataGenerationRetriever.py
Line: 27

Code:
Method: load_queries_rephrased
load_queries_rephrased
Full name: DataGeneration/Retriever/DataGenerationRetriever.py:<module>.load_queries_rephrased
Signature: load_queries_rephrased(path)
Parameters: path
Code:
def load_queries_rephrased(path):
 with open (path,'r') as f:
    data=json.load(f)
 queries=[]
 #grouped_queries=[]
 for temp in data:
    questions=temp['rephrased']

    for ques in questions:
      queries.append(ques)
 return queries

Calls methods: open, __builtin.open.<returnValue>., __iter__, load, __next__, append
In: Retriever/DataGenerationRetriever.py

--- Method 2: load_data_fiass ---
File: DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py
Line: 26

Code:
Method: load_data_fiass
load_data_fiass
Full name: DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>.load_data_fiass
Code:
def load_data_fiass():
    mean_vector = metadata["mean_vector"]
    variance_vector = metadata["variance_vector"]
    qid2emb = metadata["qid2emb"]
    qid2id = metadata["qid2id"]

    # Prepare and normalize the embeddings
    qids = list(qid2emb.keys())
    embeddings = np.array([qid2emb[qid].squeeze() for qid in qids])
    embeddings_normalized = (embeddings - mean_vector) / np.sqrt(variance_vector)
    index_f = faiss.IndexFlatIP(1024)
    res = faiss.StandardGpuResources()  # Initialize GPU resources
    gpu_index = faiss.index_cpu_to_gpu(res, 0, index_f)
    embed=normalize(embeddings_normalized,axis=1)
    gpu_index.add(embed)
    return gpu_index

gpu_index=load_data_fiass()

print('Data Indexed on FIASS')

utility=MiimansaUtility(gpu_index,metadata,direct_hit_model)

print('Utility Loaded')
# RAG = MiimansaClinicalTextRetriever.from_index(
#     "output/colbert/indexes/Colbert-Experimental"
# )
# retriever = RAG.as_langchain_retriever(
#     metadata=metadata,
#     direct_hit_model=direct_hit_model,
#     direct_hit_threshold=0.91,
#     log_direct_hit=False,
#     log_dir="./logs",
#     k=5,
# )


Calls methods: add, list<meta>, array, __init__, index_cpu_to_gpu, normalize, keys, sqrt, __iter__, append, __next__, squeeze
In: DirectHitModule/Direct_Hit_DataGeneration-FAISS.py

--- Method 3: load_queries_rephrased ---
File: DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py
Line: 74

Code:
Method: load_queries_rephrased
load_queries_rephrased
Full name: DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>.load_queries_rephrased
Signature: load_queries_rephrased(path)
Parameters: path
Code:
def load_queries_rephrased(path):
 with open (path,'r') as f:
    data=json.load(f)
 queries=[]
 #grouped_queries=[]
 for temp in data:
    questions=temp['rephrased']

    for ques in questions:
      queries.append(ques)
 return queries

Calls methods: open, __builtin.open.<returnValue>., __iter__, load, __next__, append
In: DirectHitModule/Direct_Hit_DataGeneration-FAISS.py

--- Method 4: load_json ---
File: DataGeneration/recall_calculation.py
Line: 3

Code:
Method: load_json
load_json
Full name: DataGeneration/recall_calculation.py:<module>.load_json
Signature: load_json(path)
Parameters: path
Code:
def load_json(path):
    with open(path,'r') as f:
        out= json.load(f)
    return out

Calls methods: open, __builtin.open.<returnValue>., load
In: DataGeneration/recall_calculation.py

--- Method 5: load_data ---
File: FineTuneSentenceTransformer.py
Line: 20

Code:
Method: load_data
load_data
Full name: FineTuneSentenceTransformer.py:<module>.load_data
Signature: load_data(path)
Parameters: path
Code:
def load_data(path):
    with open(path,'rb') as f:
        return pickle.load(f)


Calls methods: open, __builtin.open.<returnValue>., load
File: FineTuneSentenceTransformer.py

--- Method 6: main ---
File: FineTuneSentenceTransformer.py
Line: 168

Code:
Method: main
main
Full name: FineTuneSentenceTransformer.py:<module>.main
Code:
def main():

    anchor = load_data('anchor.pkl')
    positives = load_data('positives.pkl')
    negatives = load_data('negatives.pkl')

    model = SentenceTransformer("mixedbread-ai/mxbai-embed-large-v1")
    print('Initial Model loaded')

    #train_dataset=create_traing_data_cosine(anchor,positives,negatives)
    #test_dataset=create_test_data_cosine('rephrased_questions_cleaned_with_context.json')
    train_dataset,test_dataset=create_train_test_data_cosine_questions('rephrased_questions_cleaned_with_context.json')
    print('Dataset_loaded')
    loss=losses.CosineSimilarityLoss(model)

    args=load_args()

    custom_evaluator = CustomTripletEvaluator(
        sentence1=test_dataset["sentence1"],
        sentence2=test_dataset["sentence2"],
        score=test_dataset["score"],
        name="rephrased_questions",
    )

    # Run the evaluation
    accuracy = custom_evaluator(model)
    print(f"Initial evaluation accuracy: {accuracy}")

    trainer = SentenceTransformerTrainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    loss=loss,
    evaluator=custom_evaluator,
)
    print('Trainer loaded')
    trainer.train()


if __name__ == "__main__" :
    main()
Calls methods: print, train, load_data, __init__, load_args, create_train_test_data_cosine_questions
File: FineTuneSentenceTransformer.py

--- Method 7: load_args ---
File: FineTuneSentenceTransformer.py
Line: 145

Code:
Method: load_args
load_args
Full name: FineTuneSentenceTransformer.py:<module>.load_args
Code:
def load_args():
    return  SentenceTransformerTrainingArguments(
    # Required parameter:
    output_dir="models/fine_tune_direct_hit_questions",
    # Optional training parameters:
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    learning_rate=2e-5,
    warmup_ratio=0.1,

    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch
    # Optional tracking/debugging parameters:
    eval_strategy="steps",
    eval_steps=10,
    save_strategy="steps",
    save_steps=50,
    logging_steps=10,
    save_total_limit=1,
    load_best_model_at_end=True

)

Calls methods: __init__
File: FineTuneSentenceTransformer.py

--- Method 8: load_queries ---
File: DataGeneration/Retriever/DataGenerationRetriever.py
Line: 16

Code:
Method: load_queries
load_queries
Full name: DataGeneration/Retriever/DataGenerationRetriever.py:<module>.load_queries
Signature: load_queries(path)
Parameters: path
Code:
def load_queries(path):
 with open (path,'r') as f:
    data=json.load(f)
 queries=[]
 for temp in data:
     for qa in temp['qas']:
         for key,value in qa.items():
             if(key=='question'):
               queries.append(value)
 return queries

Calls methods: open, __builtin.open.<returnValue>., __iter__, load, __next__, items, append
In: Retriever/DataGenerationRetriever.py

--- Method 9: combine_labels ---
File: DataGeneration/recall_calculation.py
Line: 124

Code:
Method: combine_labels
combine_labels
Full name: DataGeneration/recall_calculation.py:<module>.combine_labels
Signature: combine_labels(path1, path2)
Parameters: path1, path2
Code:
def combine_labels(path1,path2):
     label1=load_json(path1)
     label2=load_json(path2)
     total=len(label1)
     for key,value in label2.items():
          k=str(int(key)+total)
          label1[k]=value
     return label1


Calls methods: load_json, len, __iter__, items, __next__, str<meta>, int<meta>
In: DataGeneration/recall_calculation.py

================================================================================
CODE RELATIONSHIPS
================================================================================
IMPORTANT: The relationships below show which methods call the methods above.
Pay special attention to class names and file paths in the 'Called by' section -
they often reveal the main components and algorithms in the codebase.

--- Method 1: load_queries_rephrased ---

✓ CALLED BY (4):
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>.main
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>.main

Calls (6):
  • open
  • __builtin.open.<returnValue>.
  • __iter__
  • load
  • __next__
  • append

--- Method 2: load_data_fiass ---

✓ CALLED BY (1):
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>

Calls (12):
  • add
  • list<meta>
  • array
  • __init__
  • index_cpu_to_gpu
  • normalize
  • keys
  • sqrt
  • __iter__
  • append

--- Method 3: load_queries_rephrased ---

✓ CALLED BY (4):
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>.main
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>.main

Calls (6):
  • open
  • __builtin.open.<returnValue>.
  • __iter__
  • load
  • __next__
  • append

--- Method 4: load_json ---

✓ CALLED BY (5):
  • DataGeneration/recall_calculation.py:<module>
  • DataGeneration/recall_calculation.py:<module>.combine_labels
  • DataGeneration/recall_calculation.py:<module>.compute_recall_direct_hit
  • DataGeneration/recall_calculation.py:<module>.compute_recall_colbert
  • DataGeneration/recall_calculation.py:<module>.compute_recall_both

Calls (3):
  • open
  • __builtin.open.<returnValue>.
  • load

--- Method 5: load_data ---

✓ CALLED BY (3):
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>
  • FineTuneSentenceTransformer.py:<module>
  • FineTuneSentenceTransformer.py:<module>.main

Calls (3):
  • open
  • __builtin.open.<returnValue>.
  • load

--- Method 6: main ---

✓ CALLED BY (4):
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>
  • DataGeneration/recall_calculation.py:<module>
  • FineTuneSentenceTransformer.py:<module>

Calls (6):
  • print
  • train
  • load_data
  • __init__
  • load_args
  • create_train_test_data_cosine_questions

--- Method 7: load_args ---

✓ CALLED BY (2):
  • FineTuneSentenceTransformer.py:<module>
  • FineTuneSentenceTransformer.py:<module>.main

Calls (1):
  • __init__

--- Method 8: load_queries ---

✓ CALLED BY (4):
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>
  • DataGeneration/DirectHitModule/Direct_Hit_DataGeneration-FAISS.py:<module>.main
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>
  • DataGeneration/Retriever/DataGenerationRetriever.py:<module>.main

Calls (7):
  • open
  • __builtin.open.<returnValue>.
  • __iter__
  • load
  • __next__
  • items
  • append

--- Method 9: combine_labels ---

✓ CALLED BY (4):
  • DataGeneration/recall_calculation.py:<module>
  • DataGeneration/recall_calculation.py:<module>.compute_recall_direct_hit
  • DataGeneration/recall_calculation.py:<module>.compute_recall_colbert
  • DataGeneration/recall_calculation.py:<module>.compute_recall_both

Calls (7):
  • load_json
  • len
  • __iter__
  • items
  • __next__
  • str<meta>
  • int<meta>

================================================================================
TASK
================================================================================

Answer the question above using the code methods and relationships provided.

Rules:
- Only use information from the methods and relationships shown above
- Extract class names, algorithm names, and file paths from the "Called by" lists in the CODE RELATIONSHIPS section
- Only mention files that appear in the "File:" lines above
- Write a direct answer without phrases like "the provided code shows" or "based on the code above"
- If information is missing, say so clearly

Answer:

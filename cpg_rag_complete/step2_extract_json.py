#!/usr/bin/env python3
"""
step2_semantic_full.py

Step 2 (FULL SEMANTIC): AST-first extraction with optional Joern enrichment.

- Extracts functions/methods with AST (Python)
- Gathers intra-file calls and best-effort callee names
- Builds indexes and resolves callees to internal methods where possible
- Creates deterministic external nodes for unresolved callees
- Optionally runs Joern to enrich metadata (fullName/signature) and merges results
- Filters synthetic / autogenerated names
- Writes: cpg_nodes.json, cpg_edges.json, methods.json, calls.json, codebase_stats.json

Usage:
    python step2_semantic_full.py /path/to/cpg.bin --source-dir /path/to/project --output data/ --joern-path ./joern-cli
"""

from __future__ import annotations
import argparse
import ast
import hashlib
import json
import os
import re
import shutil
import subprocess
import sys
import tempfile
from collections import defaultdict, deque
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

# -----------------------------
# Utilities
# -----------------------------
def stable_id(s: str) -> int:
    """Deterministic integer id from string (shortened hex)."""
    h = hashlib.md5(s.encode("utf-8")).hexdigest()
    return int(h[:15], 16)

SYNTHETIC_PATTERNS = [
    re.compile(r'^\s*<.*>\s*$'),          # <init>, <body>, <module>
    re.compile(r'^operator[._]'),         # operator.add, operator.mul
    re.compile(r'^fake[:._]', re.I),      # fake:New
    re.compile(r'metaClass', re.I),
    re.compile(r'^\s*<module>\s*$', re.I),
    re.compile(r'^\s*<unknown>\s*$', re.I),
]

def is_synthetic_name(name: Optional[str]) -> bool:
    if not name:
        return True
    s = str(name).strip()
    if s == "":
        return True
    for p in SYNTHETIC_PATTERNS:
        if p.search(s):
            return True
    if re.fullmatch(r'[^A-Za-z0-9_]+', s):
        return True
    return False

def get_source_segment(text: str, start: int, end: int) -> str:
    """Return inclusive line slice start..end (1-based)."""
    lines = text.splitlines(keepends=True)
    if start <= 0:
        start = 1
    if end < start:
        end = start
    return "".join(lines[start-1:end])

# -----------------------------
# AST extraction
# -----------------------------
@dataclass
class FunctionInfo:
    name: str
    filename: str   # relative path
    lineNumber: int
    lineNumberEnd: int
    code: str
    is_method: bool
    id: int

    @classmethod
    def from_parsed(cls, name, filename, lineno, end_lineno, code, is_method=False):
        sid = stable_id(f"{filename}::{name}::{lineno}")
        return cls(name=name, filename=filename, lineNumber=lineno,
                   lineNumberEnd=end_lineno, code=code, is_method=is_method, id=sid)

    def to_node(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "_label": "METHOD",
            "name": self.name,
            "fullName": self.name,
            "filename": self.filename,
            "lineNumber": self.lineNumber,
            "lineNumberEnd": self.lineNumberEnd,
            "code": self.code,
            "signature": "",
            "isExternal": False,
        }

    def to_method(self) -> Dict[str, Any]:
        return self.to_node()

def dotted_name(node: ast.AST) -> Optional[str]:
    """Best-effort dotted name from an AST node (Name/Attribute)."""
    if isinstance(node, ast.Name):
        return node.id
    if isinstance(node, ast.Attribute):
        parts = []
        cur = node
        while isinstance(cur, ast.Attribute):
            parts.append(cur.attr)
            cur = cur.value
        if isinstance(cur, ast.Name):
            parts.append(cur.id)
            return ".".join(reversed(parts))
    return None

def extract_functions_and_calls(py_path: Path, source_root: Path) -> Tuple[List[FunctionInfo], List[Dict[str,Any]]]:
    """
    Parse a Python file and return (functions, calls)
    calls: list of dicts { caller_id, caller_name, caller_filename, callee_name (dotted or <complex>), lineno }
    """
    try:
        text = py_path.read_text(encoding="utf-8")
    except Exception:
        return [], []

    try:
        module = ast.parse(text)
    except Exception:
        return [], []

    relpath = str(py_path.relative_to(source_root))
    functions: List[FunctionInfo] = []
    calls: List[Dict[str,Any]] = []
    class_stack: List[str] = []

    class FuncVisitor(ast.NodeVisitor):
        def visit_ClassDef(self, node: ast.ClassDef):
            class_stack.append(node.name)
            self.generic_visit(node)
            class_stack.pop()

        def visit_FunctionDef(self, node: ast.FunctionDef):
            handle_function(node)
            self.generic_visit(node)

        def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):
            handle_function(node)
            self.generic_visit(node)

    def handle_function(node: ast.AST):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            if class_stack:
                fname = f"{class_stack[-1]}.{node.name}"
                is_method = True
            else:
                fname = node.name
                is_method = False
            end_lineno = getattr(node, "end_lineno", node.lineno)
            code_seg = get_source_segment(text, node.lineno, end_lineno)
            fi = FunctionInfo.from_parsed(fname, relpath, node.lineno, end_lineno, code_seg, is_method)
            functions.append(fi)

            # visit CALLs inside function
            class CallVisitor(ast.NodeVisitor):
                def visit_Call(self, cnode: ast.Call):
                    cal = dotted_name(cnode.func)
                    lineno = getattr(cnode, "lineno", node.lineno)
                    calls.append({
                        "caller_filename": relpath,
                        "caller_name": fi.name,
                        "caller_id": fi.id,
                        "callee_name": cal if cal else "<complex>",
                        "lineno": lineno
                    })
                    self.generic_visit(cnode)
            CallVisitor().visit(node)

    visitor = FuncVisitor()
    visitor.visit(module)
    return functions, calls

# -----------------------------
# Index & call resolution
# -----------------------------
def build_index(functions: List[FunctionInfo]) -> Dict[str, Any]:
    by_file_name = {}
    by_name = defaultdict(list)
    by_id = {}
    for f in functions:
        key = (f.filename, f.name)
        by_file_name[key] = f
        by_name[f.name].append(f)
        by_id[f.id] = f
    return {"by_file_name": by_file_name, "by_name": by_name, "by_id": by_id}

def resolve_callee(callee_name: Optional[str], caller: FunctionInfo, index: Dict[str, Any]) -> Tuple[int, str, bool]:
    """
    Resolve callee_name -> (dst_id, display_name, internal_bool)
    internal_bool True if resolved to internal method
    """
    if not callee_name or callee_name == "<complex>":
        ext_name = "<complex_call>"
        return stable_id(ext_name), ext_name, False

    # exact same-file match
    key = (caller.filename, callee_name)
    if key in index["by_file_name"]:
        return index["by_file_name"][key].id, callee_name, True

    # self./cls. methods within same class
    if (callee_name.startswith("self.") or callee_name.startswith("cls.")) and "." in caller.name:
        class_name = caller.name.split(".",1)[0]
        method_part = callee_name.split(".",1)[1]
        candidate_key = (caller.filename, f"{class_name}.{method_part}")
        if candidate_key in index["by_file_name"]:
            return index["by_file_name"][candidate_key].id, f"{class_name}.{method_part}", True

    # global name match
    if callee_name in index["by_name"]:
        candidates = index["by_name"][callee_name]
        # prefer same file candidate
        for c in candidates:
            if c.filename == caller.filename:
                return c.id, c.name, True
        # otherwise return first candidate
        return candidates[0].id, candidates[0].name, True

    # dotted names: try last token match
    if "." in callee_name:
        last = callee_name.split(".")[-1]
        if last in index["by_name"]:
            c = index["by_name"][last][0]
            return c.id, c.name, True

    # not found -> deterministic external
    ext_id = stable_id(f"external::{callee_name}")
    return ext_id, callee_name, False

# -----------------------------
# Joern enrichment
# -----------------------------
def find_joern(joern_cli_path: Optional[str] = None) -> Optional[str]:
    if joern_cli_path:
        p = Path(joern_cli_path)
        if p.is_dir():
            cand = p / "joern"
            if cand.exists():
                return str(cand)
        if p.exists() and p.name == "joern":
            return str(p)
    joern = shutil.which("joern")
    if joern:
        return joern
    cwd = Path.cwd()
    fallbacks = [cwd / "joern-cli" / "joern", cwd.parent / "joern-cli" / "joern", Path.home() / "joern" / "joern-cli" / "joern"]
    for p in fallbacks:
        if p.exists():
            return str(p)
    return None

def run_joern_export(cpg_path: str, out_dir: Path, joern_path: Optional[str]) -> Tuple[List[Dict], List[Dict]]:
    """
    Run Joern script to export methods + calls as JSON.
    Returns (joern_methods, joern_calls)
    If Joern missing or fails, returns ([], [])
    """
    joern_exec = find_joern(joern_path)
    if not joern_exec:
        return [], []
    script = f'''
importCpg("{cpg_path}")
try:
  new java.io.PrintWriter("{out_dir}/joern_methods.json") {{ write(cpg.method.toJsonPretty); close }}
except Exception as e:
  println("joern methods failed: " + e.getMessage)
try:
  new java.io.PrintWriter("{out_dir}/joern_calls.json") {{ write(cpg.call.toJsonPretty); close }}
except Exception as e:
  println("joern calls failed: " + e.getMessage)
'''
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".sc", mode="w")
    tmp.write(script)
    tmp.close()
    try:
        proc = subprocess.run([joern_exec, "--script", tmp.name], capture_output=True, text=True, timeout=600)
    except Exception:
        try:
            os.unlink(tmp.name)
        except Exception:
            pass
        return [], []
    try:
        os.unlink(tmp.name)
    except Exception:
        pass

    jm = out_dir / "joern_methods.json"
    jc = out_dir / "joern_calls.json"
    j_methods = []
    j_calls = []
    if jm.exists():
        try:
            j_methods = json.loads(jm.read_text(encoding="utf-8"))
        except Exception:
            j_methods = []
    if jc.exists():
        try:
            j_calls = json.loads(jc.read_text(encoding="utf-8"))
        except Exception:
            j_calls = []
    return j_methods, j_calls

# -----------------------------
# Stats & persistence
# -----------------------------
def compute_stats(methods: List[Dict]) -> Dict[str,Any]:
    stats = {"total_methods": len(methods), "total_lines": 0, "files": {}, "largest_methods": []}
    for m in methods:
        ln = (m.get("lineNumberEnd") or m.get("lineNumber") or 0) - (m.get("lineNumber") or 0) + 1
        if ln < 0:
            ln = 0
        stats["total_lines"] += ln
        f = m.get("filename") or "unknown"
        stats["files"].setdefault(f, {"methods":0,"lines":0})
        stats["files"][f]["methods"] += 1
        stats["files"][f]["lines"] += ln
    stats["total_files"] = len(stats["files"])
    arr = []
    for m in methods:
        ln = (m.get("lineNumberEnd") or m.get("lineNumber") or 0) - (m.get("lineNumber") or 0) + 1
        if ln < 0: ln = 0
        arr.append({"name": m.get("name"), "filename": m.get("filename"), "lineNumber": m.get("lineNumber"), "line_count": ln})
    stats["largest_methods"] = sorted(arr, key=lambda x: x["line_count"], reverse=True)[:10]
    return stats

def save_all(out_dir: Path, nodes: List[Dict], edges: List[Dict], methods: List[Dict], calls: List[Dict], stats: Dict):
    out_dir.mkdir(parents=True, exist_ok=True)
    (out_dir / "cpg_nodes.json").write_text(json.dumps(nodes, indent=2), encoding="utf-8")
    (out_dir / "cpg_edges.json").write_text(json.dumps(edges, indent=2), encoding="utf-8")
    (out_dir / "methods.json").write_text(json.dumps(methods, indent=2), encoding="utf-8")
    (out_dir / "calls.json").write_text(json.dumps(calls, indent=2), encoding="utf-8")
    (out_dir / "codebase_stats.json").write_text(json.dumps(stats, indent=2), encoding="utf-8")

# -----------------------------
# Main pipeline
# -----------------------------
def main():
    parser = argparse.ArgumentParser(description="Step 2 (FULL SEMANTIC): AST-first extraction with Joern enrichment (optional)")
    parser.add_argument("cpg_file", help="Path to CPG binary (used only for Joern enrichment)")
    parser.add_argument("--source-dir", "-s", help="Source root for AST parsing (recommended)")
    parser.add_argument("--output", "-o", default="data/", help="Output directory (default: data/)")
    parser.add_argument("--joern-path", help="Path to joern-cli (optional)")
    parser.add_argument("--no-joern", action="store_true", help="Do not attempt Joern enrichment")
    args = parser.parse_args()

    cpg_path = Path(args.cpg_file)
    out_dir = Path(args.output)
    source_root = Path(args.source_dir) if args.source_dir else None

    if not cpg_path.exists():
        print(" CPG file not found:", cpg_path)
        sys.exit(1)

    print("="*60)
    print("Step 2: FULL SEMANTIC extraction (AST-first + Joern enrichment)")
    print("="*60)
    print("Input CPG:", cpg_path)
    print("Output dir:", out_dir)
    if source_root:
        print("Source dir:", source_root)
    else:
        print("Warning: no source dir provided. AST extraction will be skipped (Joern-only fallback may be less precise).")

    all_funcs: List[FunctionInfo] = []
    all_calls_raw: List[Dict[str,Any]] = []

    # 1) AST extraction if source provided
    if source_root and source_root.exists():
        py_files = list(source_root.rglob("*.py"))
        print(f"Scanning {len(py_files)} Python files for functions/calls...")
        for p in py_files:
            funcs, calls = extract_functions_and_calls(p, source_root)
            all_funcs.extend(funcs)
            all_calls_raw.extend(calls)
        print(f"  → AST extracted {len(all_funcs)} functions across {len(py_files)} files")
    else:
        print("Skipping AST extraction (no source dir)")

    # filter synthetic functions (keep them out of internal set)
    before_cnt = len(all_funcs)
    all_funcs = [f for f in all_funcs if not is_synthetic_name(f.name)]
    if len(all_funcs) != before_cnt:
        print(f"  Filtered synthetic names: removed {before_cnt - len(all_funcs)} functions")

    # 2) Build index
    index = build_index(all_funcs)

    # 3) Resolve calls -> internal/external nodes
    resolved_calls = []
    external_nodes: Dict[str, Dict] = {}
    for c in all_calls_raw:
        caller_id = c.get("caller_id")
        caller_info = index["by_id"].get(caller_id)
        if not caller_info:
            # skip unknown caller (shouldn't commonly happen)
            continue
        callee_name = c.get("callee_name")
        dst_id, resolved_name, is_internal = resolve_callee(callee_name, caller_info, index)
        # create external node if needed
        if not is_internal and resolved_name not in external_nodes:
            node = {
                "id": dst_id,
                "_label": "EXTERNAL",
                "name": resolved_name,
                "fullName": resolved_name,
                "filename": "",
                "lineNumber": 0,
                "lineNumberEnd": 0,
                "code": "",
                "signature": "",
                "isExternal": True
            }
            external_nodes[resolved_name] = node
        # append call record
        resolved_calls.append({
            "src": caller_id,
            "dst": dst_id,
            "label": "CALL",
            "callee_name": resolved_name,
            "lineno": c.get("lineno"),
            "file": c.get("caller_filename"),
            "caller_name": c.get("caller_name")
        })

    # 4) Prepare nodes and methods list
    nodes = []
    methods_out = []
    for f in all_funcs:
        nodes.append(f.to_node())
        methods_out.append(f.to_method())

    # add external nodes
    for n in external_nodes.values():
        nodes.append(n)

    # 5) Add edges list
    edges = [{"src": r["src"], "dst": r["dst"], "label": r.get("label","CALL")} for r in resolved_calls]

    # 6) Optional Joern enrichment (merge minimal metadata)
    j_methods, j_calls = [], []
    if not args.no_joern and find_joern(args.joern_path):
        print("Attempting Joern enrichment (optional) — this may take a while...")
        try:
            j_methods, j_calls = run_joern_export(str(cpg_path), out_dir, args.joern_path)
            print(f"  → Joern exports: methods={len(j_methods)} calls={len(j_calls)}")
        except Exception as e:
            print("  Joern export failed:", e)
            j_methods, j_calls = [], []
    else:
        if args.no_joern:
            print("Joern enrichment explicitly disabled (--no-joern).")
        else:
            print("Joern not found or not configured. Skipping Joern enrichment.")

    # Merge minimal metadata from Joern by matching (filename, lineNumber)
    if j_methods:
        jm_map = {}
        for jm in j_methods:
            k = (jm.get("filename"), jm.get("lineNumber"))
            jm_map[k] = jm
        enriched = 0
        for m in methods_out:
            k = (m.get("filename"), m.get("lineNumber"))
            if k in jm_map:
                jm = jm_map[k]
                if jm.get("fullName"):
                    m["fullName"] = jm.get("fullName")
                if jm.get("signature"):
                    m["signature"] = jm.get("signature")
                enriched += 1
        print(f"  → Merged Joern metadata into {enriched} methods")

    # 7) Stats + save
    stats = compute_stats(methods_out)
    save_all(out_dir, nodes, edges, methods_out, resolved_calls, stats)

    # summary
    print("\nSaved:")
    print(f"  - {len(nodes)} nodes -> {out_dir/'cpg_nodes.json'}")
    print(f"  - {len(edges)} edges -> {out_dir/'cpg_edges.json'}")
    print(f"  - {len(methods_out)} methods -> {out_dir/'methods.json'}")
    print(f"  - {len(resolved_calls)} calls -> {out_dir/'calls.json'}")
    print(f"  - stats -> {out_dir/'codebase_stats.json'}")
    print("\nCodebase stats (sample):")
    print("  Files:", stats.get("total_files"))
    print("  Methods:", stats.get("total_methods"))
    print("  Lines:", stats.get("total_lines"))
    print("\n Step 2 (FULL SEMANTIC) complete.")

if __name__ == "__main__":
    main()
